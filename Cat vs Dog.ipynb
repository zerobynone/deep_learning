{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52ffa306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "using cpu device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets,transforms\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shutil, os\n",
    "%matplotlib inline\n",
    "is_cuda=False\n",
    "if torch.cuda.is_available():\n",
    "    is_cuda = True\n",
    "print(is_cuda)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52ce8a82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Deep Learning\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7156dae6",
   "metadata": {},
   "source": [
    "# Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13f6272c",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset_dir = '/Users/User/Deep Learning/train/train'\n",
    "base_dir = '/Users/User/Deep Learning/catsdogs'\n",
    "os.mkdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c0c935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(base_dir, 'train')\n",
    "os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(base_dir,'test')\n",
    "os.mkdir(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "372a9789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dir\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "os.mkdir(train_cats_dir)\n",
    "os.mkdir(train_dogs_dir)\n",
    "\n",
    "# valid dir\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "os.mkdir(validation_cats_dir)\n",
    "os.mkdir(validation_dogs_dir)\n",
    "\n",
    "# test dir\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
    "os.mkdir(test_cats_dir)\n",
    "os.mkdir(test_dogs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b138de13",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f9a6eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cats 0~999\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range (1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0dd0ce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fnames in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fnames)\n",
    "    dst = os.path.join(train_cats_dir, fnames)\n",
    "    shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c1ae21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dogs 0~999\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fnames in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fnames)\n",
    "    dst = os.path.join(train_dogs_dir, fnames)\n",
    "    shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b9c7ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid dset\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000,1500)]\n",
    "for fnames in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fnames)\n",
    "    dst = os.path.join(validation_cats_dir, fnames)\n",
    "    shutil.copyfile(src,dst)\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000,1500)]\n",
    "for fnames in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fnames)\n",
    "    dst = os.path.join(validation_dogs_dir, fnames)\n",
    "    shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc3ac2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dset\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1500,2000)]\n",
    "for fnames in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fnames)\n",
    "    dst = os.path.join(test_cats_dir, fnames)\n",
    "    shutil.copyfile(src,dst)\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1500,2000)]\n",
    "for fnames in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fnames)\n",
    "    dst = os.path.join(test_dogs_dir, fnames)\n",
    "    shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9cef914d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 고양이 이미지 개수: 1000\n",
      "훈련용 강아지 이미지 개수: 1000\n",
      "검증용 고양이 이미지 개수: 500\n",
      "검증용 강아지 이미지 개수: 500\n",
      "테스트용 고양이 이미지 개수: 500\n",
      "테스트용 강아지 이미지 개수: 500\n"
     ]
    }
   ],
   "source": [
    "print('훈련용 고양이 이미지 개수:', len(os.listdir(train_cats_dir)))\n",
    "print('훈련용 강아지 이미지 개수:', len(os.listdir(train_dogs_dir)))\n",
    "print('검증용 고양이 이미지 개수:', len(os.listdir(validation_cats_dir)))\n",
    "print('검증용 강아지 이미지 개수:', len(os.listdir(validation_dogs_dir)))\n",
    "print('테스트용 고양이 이미지 개수:', len(os.listdir(test_cats_dir)))\n",
    "print('테스트용 강아지 이미지 개수:', len(os.listdir(test_dogs_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda642ca",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ef3ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7102ed8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-f3b162dbf316>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     transforms.ToTensor()])\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtrain_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "transformation = transforms.Compose([\n",
    "    transforms.Resize(150),\n",
    "    transforms.ToTensor()],\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=128,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=128,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eaf83d09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "469"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f3abbff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "print(images.shape)\n",
    "## images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3aa8107a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit = images[0][0]\n",
    "plt.imshow(digit, cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f9569b",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "47bb844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size = 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size = 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64,128, kernel_size =  3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(128, 128, kernel_size = 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(7*7*128,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = main(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c48ce98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "if is_cuda:\n",
    "    model.cuda()\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3c734c56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (10): ReLU()\n",
      "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (12): Flatten(start_dim=1, end_dim=-1)\n",
      "    (13): Linear(in_features=6272, out_features=512, bias=True)\n",
      "    (14): ReLU()\n",
      "    (15): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (16): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97b76b7",
   "metadata": {},
   "source": [
    "# Define Train & Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4fd4851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # forward\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred,y)\n",
    "        \n",
    "        # backward \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch %100 == 0:\n",
    "            loss, current = loss.item(), batch*len(X)\n",
    "            print(f\"loss: {loss:>7f}[{current:>5d}/{size:5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c08599e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():           # data 추적 X (inference)\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred,y).item()\n",
    "            correct += (pred.argmax(1)==y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da60d57",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7cd976a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 1 \n",
      "\n",
      "loss: 2.301043[    0/60000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-77-ff1da966f3e6>:23: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.278916[12800/60000]\n",
      "loss: 2.246586[25600/60000]\n",
      "loss: 1.737397[38400/60000]\n",
      "loss: 0.635253[51200/60000]\n",
      "test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.497084 \n",
      "\n",
      "Epochs 2 \n",
      "\n",
      "loss: 0.577704[    0/60000]\n",
      "loss: 0.303544[12800/60000]\n",
      "loss: 0.433257[25600/60000]\n",
      "loss: 0.288564[38400/60000]\n",
      "loss: 0.210045[51200/60000]\n",
      "test Error: \n",
      " Accuracy: 90.3%, Avg loss: 0.302502 \n",
      "\n",
      "Epochs 3 \n",
      "\n",
      "loss: 0.310425[    0/60000]\n",
      "loss: 0.352538[12800/60000]\n",
      "loss: 0.234307[25600/60000]\n",
      "loss: 0.211240[38400/60000]\n",
      "loss: 0.216073[51200/60000]\n",
      "test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.183339 \n",
      "\n",
      "Epochs 4 \n",
      "\n",
      "loss: 0.207256[    0/60000]\n",
      "loss: 0.212312[12800/60000]\n",
      "loss: 0.141016[25600/60000]\n",
      "loss: 0.277284[38400/60000]\n",
      "loss: 0.278368[51200/60000]\n",
      "test Error: \n",
      " Accuracy: 95.7%, Avg loss: 0.139161 \n",
      "\n",
      "Epochs 5 \n",
      "\n",
      "loss: 0.110113[    0/60000]\n",
      "loss: 0.128667[12800/60000]\n",
      "loss: 0.175172[25600/60000]\n",
      "loss: 0.215797[38400/60000]\n",
      "loss: 0.069492[51200/60000]\n",
      "test Error: \n",
      " Accuracy: 96.8%, Avg loss: 0.107269 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = \n",
    "for t in range(epochs):\n",
    "    print(f\"Epochs {t+1} \\n\")\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "    test(test_loader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
