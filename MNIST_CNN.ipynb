{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "52ffa306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "using cpu device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets,transforms\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "is_cuda=False\n",
    "if torch.cuda.is_available():\n",
    "    is_cuda = True\n",
    "print(is_cuda)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b138de13",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7102ed8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transformation = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.MNIST('data/',train=True,transform=transformation,download=True)\n",
    "test_dataset = datasets.MNIST('data/',train=False,transform=transformation,download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=128,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=128,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eaf83d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "469"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f3abbff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "print(images.shape)\n",
    "## images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3aa8107a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit = images[0][0]\n",
    "plt.imshow(digit, cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f9569b",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "47bb844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,32, kernel_size = 3)\n",
    "        self.conv2 = nn.Conv2d(32,64, kernel_size = 3)\n",
    "        self.conv3 = nn.Conv2d(64,64, kernel_size = 3)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(576,64)\n",
    "        self.fc2 = nn.Linear(64,10)\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c48ce98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "if is_cuda:\n",
    "    model.cuda()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3c734c56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Net.forward of Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=576, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(model.forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97b76b7",
   "metadata": {},
   "source": [
    "# Define Train & Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4fd4851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # forward\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred,y)\n",
    "        \n",
    "        # backward \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch %100 == 0:\n",
    "            loss, current = loss.item(), batch*len(X)\n",
    "            print(f\"loss: {loss:>7f}[{current:>5d}/{size:5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3c08599e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():           # data 추적 X (inference)\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred,y).item()\n",
    "            correct += (pred.argmax(1)==y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da60d57",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7cd976a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 1 \n",
      "\n",
      "loss: 2.301043[    0/60000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-77-ff1da966f3e6>:23: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.278916[12800/60000]\n",
      "loss: 2.246586[25600/60000]\n",
      "loss: 1.737397[38400/60000]\n",
      "loss: 0.635253[51200/60000]\n",
      "test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.497084 \n",
      "\n",
      "Epochs 2 \n",
      "\n",
      "loss: 0.577704[    0/60000]\n",
      "loss: 0.303544[12800/60000]\n",
      "loss: 0.433257[25600/60000]\n",
      "loss: 0.288564[38400/60000]\n",
      "loss: 0.210045[51200/60000]\n",
      "test Error: \n",
      " Accuracy: 90.3%, Avg loss: 0.302502 \n",
      "\n",
      "Epochs 3 \n",
      "\n",
      "loss: 0.310425[    0/60000]\n",
      "loss: 0.352538[12800/60000]\n",
      "loss: 0.234307[25600/60000]\n",
      "loss: 0.211240[38400/60000]\n",
      "loss: 0.216073[51200/60000]\n",
      "test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.183339 \n",
      "\n",
      "Epochs 4 \n",
      "\n",
      "loss: 0.207256[    0/60000]\n",
      "loss: 0.212312[12800/60000]\n",
      "loss: 0.141016[25600/60000]\n",
      "loss: 0.277284[38400/60000]\n",
      "loss: 0.278368[51200/60000]\n",
      "test Error: \n",
      " Accuracy: 95.7%, Avg loss: 0.139161 \n",
      "\n",
      "Epochs 5 \n",
      "\n",
      "loss: 0.110113[    0/60000]\n",
      "loss: 0.128667[12800/60000]\n",
      "loss: 0.175172[25600/60000]\n",
      "loss: 0.215797[38400/60000]\n",
      "loss: 0.069492[51200/60000]\n",
      "test Error: \n",
      " Accuracy: 96.8%, Avg loss: 0.107269 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epochs {t+1} \\n\")\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "    test(test_loader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
